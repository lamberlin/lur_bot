{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "f9adfe44-3f34-4824-826e-7fd776a4aaf5",
    "_uuid": "325c3042-e63e-4c79-8491-974d39b0d90d",
    "execution": {
     "iopub.execute_input": "2023-11-17T13:46:34.486070Z",
     "iopub.status.busy": "2023-11-17T13:46:34.485786Z",
     "iopub.status.idle": "2023-11-17T13:46:48.925676Z",
     "shell.execute_reply": "2023-11-17T13:46:48.924806Z",
     "shell.execute_reply.started": "2023-11-17T13:46:34.486045Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "with open('all_stop_words.pkl', 'rb') as file:\n",
    "    stop_words = pickle.load(file)\n",
    "def preprocess(text, tokenizer):\n",
    "    words = tokenizer.tokenize(text.lower())\n",
    "    return [w for w in words if w not in stop_words]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def text_to_bert_embedding(text, model, tokenizer):\n",
    "    model = model.to(device)\n",
    "    try:\n",
    "        tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "        input_ids = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "        embedding = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()\n",
    "        return embedding\n",
    "    except:\n",
    "        return [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "1c469370-7c72-42da-9d6d-5e6a9f1035a9",
    "_uuid": "e7be5178-603e-4295-8261-aa60f3c29d1c",
    "execution": {
     "iopub.execute_input": "2023-11-17T13:46:48.927825Z",
     "iopub.status.busy": "2023-11-17T13:46:48.927490Z",
     "iopub.status.idle": "2023-11-17T13:46:52.708032Z",
     "shell.execute_reply": "2023-11-17T13:46:52.706371Z",
     "shell.execute_reply.started": "2023-11-17T13:46:48.927792Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df= pd.read_csv(r\"./majorreview.csv\", encoding='ISO-8859-1')\n",
    "df_all= pd.read_csv(r\"./alltext.csv\", encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "university_review_counts = df_all.groupby('sub_topic')['reviews_lemmatized'].count()\n",
    "\n",
    "min_review_count = university_review_counts.min()\n",
    "\n",
    "sampled_data = []\n",
    "for topic in df_all['sub_topic'].unique():\n",
    "    sampled_topic_data = df_all[df_all['sub_topic'] == topic].sample(min_review_count, random_state=42)\n",
    "    sampled_data.append(sampled_topic_data)\n",
    "\n",
    "balanced_df_all = pd.concat(sampled_data)\n",
    "\n",
    "train_df, test_df = train_test_split(balanced_df_all, test_size=0.1, stratify=balanced_df_all['sub_topic'], random_state=42)\n",
    "test_df.to_csv('test.csv', index=False)\n",
    "train_df.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_topic\n",
      "Administration and school policies    489\n",
      "Admission process                     489\n",
      "Career opportunities                  489\n",
      "Diversity and inclusion               488\n",
      "Financial aid and scholarships        488\n",
      "General academic quality              489\n",
      "Online learning                       488\n",
      "Student opportunities                 489\n",
      "Technology and computer labs          489\n",
      "dtype: int64\n",
      "sub_topic\n",
      "Administration and school policies    489\n",
      "Admission process                     489\n",
      "Career opportunities                  489\n",
      "Diversity and inclusion               488\n",
      "Financial aid and scholarships        488\n",
      "General academic quality              489\n",
      "Online learning                       488\n",
      "Student opportunities                 489\n",
      "Technology and computer labs          489\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "topic_counts = train_df.groupby('sub_topic').size()\n",
    "train_topic_counts = train_df.groupby('sub_topic').size()\n",
    "topic_counts = test_df.groupby('sub_topic').size()\n",
    "test_topic_counts = test_df.groupby('sub_topic').size()\n",
    "print(topic_counts)\n",
    "print(train_topic_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_topic\n",
      "Administration and school policies    54\n",
      "Admission process                     54\n",
      "Career opportunities                  54\n",
      "Diversity and inclusion               55\n",
      "Financial aid and scholarships        55\n",
      "General academic quality              54\n",
      "Online learning                       55\n",
      "Student opportunities                 54\n",
      "Technology and computer labs          54\n",
      "dtype: int64\n",
      "sub_topic\n",
      "Administration and school policies    54\n",
      "Admission process                     54\n",
      "Career opportunities                  54\n",
      "Diversity and inclusion               55\n",
      "Financial aid and scholarships        55\n",
      "General academic quality              54\n",
      "Online learning                       55\n",
      "Student opportunities                 54\n",
      "Technology and computer labs          54\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(topic_counts)\n",
    "print(test_topic_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for item in train_df[\"reviews_lemmatized\"].astype(str).apply(lambda x: x.split()):\n",
    "    tmp.extend(item)\n",
    "\n",
    "users_stop_words = []\n",
    "for _ in Counter(tmp).most_common(30):\n",
    "    if _[0] in stopwords.words('english'):\n",
    "        continue\n",
    "    else:\n",
    "        users_stop_words.append(_[0])\n",
    "\n",
    "stop_words = set(stopwords.words('english')+users_stop_words)\n",
    "with open('all_stop_words.pkl', 'wb') as file:\n",
    "    pickle.dump(stop_words, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8299/8299 [14:23<00:00,  9.61it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('all_stop_words.pkl', 'rb') as file:\n",
    "    stop_words = pickle.load(file)\n",
    "\n",
    "tqdm.pandas()\n",
    "embeddings_2 = train_df[\"reviews_lemmatized\"].progress_apply(lambda x: text_to_bert_embedding(preprocess(x, tokenizer), model, tokenizer))\n",
    "\n",
    "np.save('reviews_embedding_bert.npy', \n",
    "        {'embeddings': np.vstack(embeddings_2),\n",
    "         'University': train_df[\"University\"].to_numpy(),\n",
    "         'reviews': train_df[\"reviews_lemmatized\"].to_numpy(),\n",
    "         'sub_topic': train_df[\"sub_topic\"].to_numpy(),\n",
    "         'author': train_df[\"author\"].to_numpy(),\n",
    "         'created': train_df[\"created\"].to_numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>university</th>\n",
       "      <th>WAS</th>\n",
       "      <th>Highest_Prob_Topic</th>\n",
       "      <th>Most_Relevant_Review</th>\n",
       "      <th>Most_Relevant_Author</th>\n",
       "      <th>Most_Relevant_Created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.043957</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>most class transition well to online learning ...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>2020/7/30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brown University</td>\n",
       "      <td>0.043627</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>the online experience have be positive obvious...</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>2020/8/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carnegie Mellon University</td>\n",
       "      <td>0.043229</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>cmu do a solid job transition to online learn ...</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>2020/8/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Columbia University</td>\n",
       "      <td>0.044245</td>\n",
       "      <td>Student opportunities</td>\n",
       "      <td>internship be well worth the time and they hel...</td>\n",
       "      <td>College Senior</td>\n",
       "      <td>2013/3/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cornell University</td>\n",
       "      <td>0.043431</td>\n",
       "      <td>Student opportunities</td>\n",
       "      <td>my major have the great career service departm...</td>\n",
       "      <td>College Sophomore</td>\n",
       "      <td>2014/1/8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Duke University</td>\n",
       "      <td>0.045010</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>online learning have be difficult but my profe...</td>\n",
       "      <td>Graduate Student</td>\n",
       "      <td>2021/4/6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harvard University</td>\n",
       "      <td>0.043458</td>\n",
       "      <td>Technology and computer labs</td>\n",
       "      <td>wifi everywhere computer lab in every dorm pri...</td>\n",
       "      <td>College Sophomore</td>\n",
       "      <td>2013/12/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>0.043244</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>the online learning experience with john hopki...</td>\n",
       "      <td>Graduate Student</td>\n",
       "      <td>2021/1/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>0.029402</td>\n",
       "      <td>Student opportunities</td>\n",
       "      <td>mit be a great place to find research or biote...</td>\n",
       "      <td>College Senior</td>\n",
       "      <td>2014/8/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>New York University</td>\n",
       "      <td>0.044160</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>nyu have be try but it isnt really do well wit...</td>\n",
       "      <td>Senior</td>\n",
       "      <td>2020/10/31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Northwestern University</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>i expect to have a great time in my online cla...</td>\n",
       "      <td>Graduate Student</td>\n",
       "      <td>2020/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Princeton University</td>\n",
       "      <td>0.045270</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>not worth pay tuition for mediocre online clas...</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>2020/7/29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stanford University</td>\n",
       "      <td>0.044876</td>\n",
       "      <td>Technology and computer labs</td>\n",
       "      <td>tech support for every hall and house computer...</td>\n",
       "      <td>College Freshman</td>\n",
       "      <td>2014/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>0.044546</td>\n",
       "      <td>Technology and computer labs</td>\n",
       "      <td>computer lab there be several computer labs av...</td>\n",
       "      <td>Recent Alumnus</td>\n",
       "      <td>2011/4/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>University of California, Los Angeles</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>the online experience be good the professor be...</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2020/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>University of California, San Diego</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>my professor have be very accommodate througho...</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>2021/1/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>University of California, Santa Barbara</td>\n",
       "      <td>0.043571</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>im take 3 class online the professor and stude...</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2021/3/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>University of North Carolina at Chapel Hill</td>\n",
       "      <td>0.044862</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>it alright everyone be try their best to keep ...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>2021/2/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>University of Pennsylvania</td>\n",
       "      <td>0.045396</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>only take online class once thing switch sudde...</td>\n",
       "      <td>Senior</td>\n",
       "      <td>2020/8/26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>University of Southern California</td>\n",
       "      <td>0.044688</td>\n",
       "      <td>Technology and computer labs</td>\n",
       "      <td>computer and technology be often encourage in ...</td>\n",
       "      <td>College Freshman</td>\n",
       "      <td>2014/2/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>University of Texas at Austin</td>\n",
       "      <td>0.044038</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>half of my class be online my stem teacher do ...</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2021/2/6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>University of Washington</td>\n",
       "      <td>0.043855</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>ive complete one quarter of online learning an...</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2021/1/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Yale University</td>\n",
       "      <td>0.044114</td>\n",
       "      <td>Technology and computer labs</td>\n",
       "      <td>the technology and network be top notch</td>\n",
       "      <td>College Freshman</td>\n",
       "      <td>2014/1/4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     university       WAS   \n",
       "0                             Boston University  0.043957  \\\n",
       "1                              Brown University  0.043627   \n",
       "2                    Carnegie Mellon University  0.043229   \n",
       "3                           Columbia University  0.044245   \n",
       "4                            Cornell University  0.043431   \n",
       "5                               Duke University  0.045010   \n",
       "6                            Harvard University  0.043458   \n",
       "7                      Johns Hopkins University  0.043244   \n",
       "8         Massachusetts Institute of Technology  0.029402   \n",
       "9                           New York University  0.044160   \n",
       "10                      Northwestern University  0.043875   \n",
       "11                         Princeton University  0.045270   \n",
       "12                          Stanford University  0.044876   \n",
       "13           University of California, Berkeley  0.044546   \n",
       "14        University of California, Los Angeles  0.043936   \n",
       "15          University of California, San Diego  0.043210   \n",
       "16      University of California, Santa Barbara  0.043571   \n",
       "17  University of North Carolina at Chapel Hill  0.044862   \n",
       "18                   University of Pennsylvania  0.045396   \n",
       "19            University of Southern California  0.044688   \n",
       "20                University of Texas at Austin  0.044038   \n",
       "21                     University of Washington  0.043855   \n",
       "22                              Yale University  0.044114   \n",
       "\n",
       "              Highest_Prob_Topic   \n",
       "0                Online learning  \\\n",
       "1                Online learning   \n",
       "2                Online learning   \n",
       "3          Student opportunities   \n",
       "4          Student opportunities   \n",
       "5                Online learning   \n",
       "6   Technology and computer labs   \n",
       "7                Online learning   \n",
       "8          Student opportunities   \n",
       "9                Online learning   \n",
       "10               Online learning   \n",
       "11               Online learning   \n",
       "12  Technology and computer labs   \n",
       "13  Technology and computer labs   \n",
       "14               Online learning   \n",
       "15               Online learning   \n",
       "16               Online learning   \n",
       "17               Online learning   \n",
       "18               Online learning   \n",
       "19  Technology and computer labs   \n",
       "20               Online learning   \n",
       "21               Online learning   \n",
       "22  Technology and computer labs   \n",
       "\n",
       "                                 Most_Relevant_Review Most_Relevant_Author   \n",
       "0   most class transition well to online learning ...               Junior  \\\n",
       "1   the online experience have be positive obvious...            Sophomore   \n",
       "2   cmu do a solid job transition to online learn ...            Sophomore   \n",
       "3   internship be well worth the time and they hel...       College Senior   \n",
       "4   my major have the great career service departm...    College Sophomore   \n",
       "5   online learning have be difficult but my profe...     Graduate Student   \n",
       "6   wifi everywhere computer lab in every dorm pri...    College Sophomore   \n",
       "7   the online learning experience with john hopki...     Graduate Student   \n",
       "8   mit be a great place to find research or biote...       College Senior   \n",
       "9   nyu have be try but it isnt really do well wit...               Senior   \n",
       "10  i expect to have a great time in my online cla...     Graduate Student   \n",
       "11  not worth pay tuition for mediocre online clas...            Sophomore   \n",
       "12  tech support for every hall and house computer...     College Freshman   \n",
       "13  computer lab there be several computer labs av...       Recent Alumnus   \n",
       "14  the online experience be good the professor be...             Freshman   \n",
       "15  my professor have be very accommodate througho...            Sophomore   \n",
       "16  im take 3 class online the professor and stude...             Freshman   \n",
       "17  it alright everyone be try their best to keep ...               Junior   \n",
       "18  only take online class once thing switch sudde...               Senior   \n",
       "19  computer and technology be often encourage in ...     College Freshman   \n",
       "20  half of my class be online my stem teacher do ...             Freshman   \n",
       "21  ive complete one quarter of online learning an...             Freshman   \n",
       "22            the technology and network be top notch     College Freshman   \n",
       "\n",
       "   Most_Relevant_Created  \n",
       "0              2020/7/30  \n",
       "1              2020/8/19  \n",
       "2              2020/8/24  \n",
       "3               2013/3/4  \n",
       "4               2014/1/8  \n",
       "5               2021/4/6  \n",
       "6              2013/12/1  \n",
       "7              2021/1/20  \n",
       "8              2014/8/14  \n",
       "9             2020/10/31  \n",
       "10             2020/5/20  \n",
       "11             2020/7/29  \n",
       "12             2014/5/20  \n",
       "13             2011/4/20  \n",
       "14             2020/5/20  \n",
       "15              2021/1/1  \n",
       "16              2021/3/2  \n",
       "17              2021/2/1  \n",
       "18             2020/8/26  \n",
       "19             2014/2/22  \n",
       "20              2021/2/6  \n",
       "21              2021/1/2  \n",
       "22              2014/1/4  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "embedding_file='reviews_embedding_bert.zip'\n",
    "def load_reviews(zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"extracted_data\")\n",
    "        npy_file = [f for f in os.listdir(\"extracted_data\") if f.endswith('.npy')][0]\n",
    "        npy_file_path = os.path.join(\"extracted_data\", npy_file)\n",
    "        data = np.load(npy_file_path, allow_pickle=True).item()\n",
    "        os.remove(npy_file_path)\n",
    "        os.rmdir(\"extracted_data\")\n",
    "    return data['embeddings'], data['reviews'], data['University'], data['sub_topic'], data['author'], data['created']\n",
    "\n",
    "def calculate_topic_probabilities_with_reviews(input_text, model, tokenizer, zip_file_path):\n",
    "    embeddings, reviews, universities, sub_topics, authors, created_dates = load_reviews(zip_file_path)\n",
    "    input_text_tokens = preprocess(input_text, tokenizer)\n",
    "    input_text_embedding = text_to_bert_embedding(\" \".join(input_text_tokens), model, tokenizer)\n",
    "    similarities = cosine_similarity(input_text_embedding.reshape(1, -1), embeddings).flatten()\n",
    "    topic_scores = {}\n",
    "    for score, topic in zip(similarities, sub_topics):\n",
    "        topic_scores[topic] = topic_scores.get(topic, 0) + score\n",
    "    top_topics = sorted(topic_scores, key=topic_scores.get, reverse=True)[:3]\n",
    "    total_topic_score = sum(topic_scores[topic] for topic in top_topics)\n",
    "    topic_probabilities = {topic: topic_scores[topic] / total_topic_score for topic in top_topics}\n",
    "    filtered_indices = [i for i, topic in enumerate(sub_topics) if topic in top_topics]\n",
    "    filtered_data = {\n",
    "        'sub_topic': [sub_topics[i] for i in filtered_indices],\n",
    "        'review': [reviews[i] for i in filtered_indices],\n",
    "        'similarity_score': [similarities[i] for i in filtered_indices],\n",
    "        'university': [universities[i] for i in filtered_indices],\n",
    "        'author': [authors[i] for i in filtered_indices],\n",
    "        'created': [created_dates[i] for i in filtered_indices],\n",
    "        'topic_probability': [topic_probabilities[sub_topics[i]] for i in filtered_indices]\n",
    "    }\n",
    "\n",
    "    filtered_df = pd.DataFrame(filtered_data)\n",
    "\n",
    "    return filtered_df\n",
    "def calculate_weighted_average_similarity(input_text, model, tokenizer, embedding_file):\n",
    "    filtered_df = calculate_topic_probabilities_with_reviews(input_text, model, tokenizer, embedding_file)\n",
    "    \n",
    "    filtered_df['university'] = filtered_df['university'].astype(str)\n",
    "    filtered_df['sub_topic'] = filtered_df['sub_topic'].astype(str)\n",
    "\n",
    "    mean_scores = filtered_df.groupby(['university', 'sub_topic']).agg({'similarity_score': 'mean'}).reset_index()\n",
    "    mean_scores['weighted_score'] = mean_scores.apply(\n",
    "        lambda x: x['similarity_score'] * filtered_df[filtered_df['sub_topic'] == x['sub_topic']]['topic_probability'].iloc[0], \n",
    "        axis=1\n",
    "    )\n",
    "    was_scores = mean_scores.groupby('university')['weighted_score'].sum().reset_index().rename(columns={'weighted_score': 'WAS'})\n",
    "\n",
    "    # Renormalizing the WAS scores\n",
    "    total_was = was_scores['WAS'].sum()\n",
    "    was_scores['WAS'] = was_scores['WAS'] / total_was\n",
    "\n",
    "    highest_prob_topic = mean_scores.loc[mean_scores.groupby('university')['similarity_score'].idxmax()][['university', 'sub_topic']]\n",
    "    highest_prob_topic.columns = ['university', 'Highest_Prob_Topic']\n",
    "    highest_prob_topic['university'] = highest_prob_topic['university'].astype(str)\n",
    "    highest_prob_topic['Highest_Prob_Topic'] = highest_prob_topic['Highest_Prob_Topic'].astype(str)\n",
    "\n",
    "    result = pd.merge(was_scores, highest_prob_topic, on='university')\n",
    "\n",
    "    relevant_review = filtered_df.loc[filtered_df.groupby(['university', 'sub_topic'])['similarity_score'].idxmax()][['university', 'sub_topic', 'review', 'author', 'created']]\n",
    "    relevant_review.columns = ['university', 'Highest_Prob_Topic', 'Most_Relevant_Review', 'Most_Relevant_Author', 'Most_Relevant_Created']\n",
    "    relevant_review['university'] = relevant_review['university'].astype(str)\n",
    "    relevant_review['Highest_Prob_Topic'] = relevant_review['Highest_Prob_Topic'].astype(str)\n",
    "\n",
    "    final_result = pd.merge(result, relevant_review, on=['university', 'Highest_Prob_Topic'])\n",
    "\n",
    "    return final_result[['university', 'WAS', 'Highest_Prob_Topic', 'Most_Relevant_Review', 'Most_Relevant_Author', 'Most_Relevant_Created']]\n",
    "\n",
    "def calculate_confidence_score(input_text, model, tokenizer, embedding_file):\n",
    "    df = calculate_topic_probabilities_with_reviews(input_text, model, tokenizer, embedding_file)    \n",
    "    topic_counts = df['sub_topic'].value_counts()\n",
    "    total_data_points = len(df)\n",
    "    topic_portions = topic_counts / total_data_points\n",
    "    topic_probabilities = df['topic_probability'].groupby(df['sub_topic']).mean()\n",
    "    weighted_average = sum(topic_portions * topic_probabilities)\n",
    "    return weighted_average\n",
    "\n",
    "\n",
    "input_text = \"I love multiple labs and well online learning in school\"\n",
    "\n",
    "b=calculate_weighted_average_similarity(input_text, model, tokenizer, embedding_file)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "      <th>WAS</th>\n",
       "      <th>Highest_Prob_Topic</th>\n",
       "      <th>Most_Relevant_Review</th>\n",
       "      <th>Most_Relevant_Author</th>\n",
       "      <th>Most_Relevant_Created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston University</td>\n",
       "      <td>0.044081</td>\n",
       "      <td>Campus party scene</td>\n",
       "      <td>mit definitely have the best night time event ...</td>\n",
       "      <td>College Freshman</td>\n",
       "      <td>2014/3/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brown University</td>\n",
       "      <td>0.044276</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>i havent do any online learning yet but the fe...</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>2020/6/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carnegie Mellon University</td>\n",
       "      <td>0.044340</td>\n",
       "      <td>Campus party scene</td>\n",
       "      <td>what youre expect florida state dont get me wr...</td>\n",
       "      <td>College Freshman</td>\n",
       "      <td>2011/11/6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Columbia University</td>\n",
       "      <td>0.043259</td>\n",
       "      <td>Campus party scene</td>\n",
       "      <td>the bar be pretty lame but occasionally they b...</td>\n",
       "      <td>College Sophomore</td>\n",
       "      <td>2014/3/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cornell University</td>\n",
       "      <td>0.043806</td>\n",
       "      <td>Online learning</td>\n",
       "      <td>horrible rampant cheating and no way to stop i...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>2020/7/31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   University       WAS  Highest_Prob_Topic   \n",
       "0           Boston University  0.044081  Campus party scene  \\\n",
       "1            Brown University  0.044276     Online learning   \n",
       "2  Carnegie Mellon University  0.044340  Campus party scene   \n",
       "3         Columbia University  0.043259  Campus party scene   \n",
       "4          Cornell University  0.043806     Online learning   \n",
       "\n",
       "                                Most_Relevant_Review Most_Relevant_Author   \n",
       "0  mit definitely have the best night time event ...     College Freshman  \\\n",
       "1  i havent do any online learning yet but the fe...             Freshman   \n",
       "2  what youre expect florida state dont get me wr...     College Freshman   \n",
       "3  the bar be pretty lame but occasionally they b...    College Sophomore   \n",
       "4  horrible rampant cheating and no way to stop i...               Junior   \n",
       "\n",
       "  Most_Relevant_Created  \n",
       "0             2014/3/15  \n",
       "1             2020/6/25  \n",
       "2             2011/11/6  \n",
       "3             2014/3/11  \n",
       "4             2020/7/31  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from embeddings import allEmbeddingsCalculator\n",
    "from tqdm import tqdm\n",
    "input_text = \"love college with multiple libarary\"\n",
    "embeddings_calculator = allEmbeddingsCalculator()\n",
    "b=embeddings_calculator.calculate_weighted_average_similarity(input_text)\n",
    "a=embeddings_calculator.calculate_confidence_score(input_text)\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4130879345603272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinol\\AppData\\Local\\Temp\\ipykernel_18288\\3841680629.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Predicted_University'] = predicted_universities\n",
      "C:\\Users\\dinol\\AppData\\Local\\Temp\\ipykernel_18288\\3841680629.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Match'] = test_df.apply(lambda row: row['University'] in row['Predicted_University'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "test_df= pd.read_csv(r\"./text.csv\", encoding='ISO-8859-1')\n",
    "from embeddings import allEmbeddingsCalculator\n",
    "from tqdm.auto import tqdm\n",
    "embeddings_calculator = allEmbeddingsCalculator()\n",
    "predicted_universities = []\n",
    "for review in tqdm(test_df['reviews_lemmatized'], desc=\"Processing Reviews\"):\n",
    "    preprocessed_review = \" \".join(review.lower().split())\n",
    "    result = embeddings_calculator.calculate_weighted_average_similarity(preprocessed_review)\n",
    "    top_universities = result.nlargest(5, 'WAS')['University'].tolist()\n",
    "    predicted_universities.append(top_universities)\n",
    "test_df['Predicted_University'] = predicted_universities\n",
    "test_df['Match'] = test_df.apply(lambda row: row['University'] in row['Predicted_University'], axis=1)\n",
    "accuracy = test_df['Match'].sum() / len(test_df)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df= pd.read_csv(r\"./text.csv\", encoding='ISO-8859-1')\n",
    "from embeddings import allEmbeddingsCalculator\n",
    "from tqdm.auto import tqdm\n",
    "embeddings_calculator = allEmbeddingsCalculator()\n",
    "predicted_universities = []\n",
    "for review in tqdm(test_df['reviews_lemmatized'], desc=\"Processing Reviews\"):\n",
    "    preprocessed_review = \" \".join(review.lower().split())\n",
    "    result = embeddings_calculator.calculate_weighted_average_similarity(preprocessed_review)\n",
    "    top_universities = result.nlargest(7, 'WAS')['University'].tolist()\n",
    "    predicted_universities.append(top_universities)\n",
    "test_df['Predicted_University'] = predicted_universities\n",
    "test_df['Match'] = test_df.apply(lambda row: row['University'] in row['Predicted_University'], axis=1)\n",
    "accuracy = test_df['Match'].sum() / len(test_df)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Reviews: 100%|████████████████████████████████████████████████████████████| 100/100 [00:54<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per Sub-Topic:\n",
      "sub_topic\n",
      "Administration and school policies    0.312500\n",
      "Admission process                     0.285714\n",
      "Career opportunities                  0.363636\n",
      "Diversity and inclusion               0.250000\n",
      "Financial aid and scholarships        0.181818\n",
      "General academic quality              0.250000\n",
      "Online learning                       0.333333\n",
      "Student opportunities                 0.000000\n",
      "Technology and computer labs          0.375000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from embeddings import allEmbeddingsCalculator\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "embeddings_calculator = allEmbeddingsCalculator()\n",
    "predicted_universities = []\n",
    "for review in tqdm(test_df['reviews_lemmatized'], desc=\"Processing Reviews\"):\n",
    "    preprocessed_review = \" \".join(review.lower().split())\n",
    "    result = embeddings_calculator.general_scores(preprocessed_review)\n",
    "    \n",
    "    top_universities = result.sort_values(by='WAS', ascending=False).index[:5]\n",
    "    predicted_universities.append(top_universities)\n",
    "\n",
    "test_df['Predicted_University'] = predicted_universities\n",
    "test_df['Match'] = test_df.apply(lambda row: row['University'] in row['Predicted_University'], axis=1)\n",
    "accuracy_per_sub_topic = test_df.groupby('sub_topic').apply(lambda group: group['Match'].sum() / len(group))\n",
    "print(\"Accuracy per Sub-Topic:\")\n",
    "print(accuracy_per_sub_topic)\n",
    "def weighted_accuracy(input_text, embeddings_calculator):\n",
    "    topic_probabilities_df = embeddings_calculator.calculate_topic_probabilities(input_text)\n",
    "    topic_probabilities_df = topic_probabilities_df[topic_probabilities_df['sub_topic'] != 'Student opportunities']\n",
    "    total_probability = topic_probabilities_df['topic_probability'].sum()\n",
    "    topic_probabilities_df['normalized_probability'] = topic_probabilities_df['topic_probability'] / total_probability\n",
    "    accuracy_df = pd.read_csv('accuracy_per_sub_topic.csv')\n",
    "    accuracy_df['Accuracy'] = pd.to_numeric(accuracy_df['Accuracy'], errors='coerce')\n",
    "    accuracy_dict = accuracy_df.set_index('Sub_Topic')['Accuracy'].to_dict()\n",
    "    weighted_avg_accuracy = sum(\n",
    "        topic_probabilities_df['normalized_probability'] *\n",
    "        topic_probabilities_df['sub_topic'].apply(lambda topic: accuracy_dict.get(topic, 0))\n",
    "    )\n",
    "    return weighted_avg_accuracy\n",
    "input_text = \"love college with multiple libarary\"\n",
    "weighted_accuracy_value = weighted_accuracy(input_text, embeddings_calculator)\n",
    "print(\"Weighted Average Accuracy:\", weighted_accuracy_value)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1936563,
     "sourceId": 6674905,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3969385,
     "sourceId": 6911685,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3989128,
     "sourceId": 6945917,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3994594,
     "sourceId": 6954877,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
